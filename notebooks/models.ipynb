{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook j'analyse l'architecture de différents modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alan/.cache/pypoetry/virtualenvs/sdd-2XWLAjSi-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torchvision.models.detection as D\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from transformers import AutoModelForImageClassification, AutoConfig, AutoModelForObjectDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SwinTransformer(\n",
       "  (features): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): Permute()\n",
       "      (2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.018181818181818184, mode=row)\n",
       "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): PatchMergingV2(\n",
       "      (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.03636363636363637, mode=row)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05454545454545456, mode=row)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): PatchMergingV2(\n",
       "      (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "      (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07272727272727274, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09090909090909091, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.10909090909090911, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1272727272727273, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14545454545454548, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.16363636363636364, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): PatchMergingV2(\n",
       "      (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.18181818181818182, mode=row)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2, mode=row)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (permute): Permute()\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.swin_v2_t()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.font_manager as fm\n",
    "# # fm.findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "# import os\n",
    "\n",
    "# print(os.environ[\"PYTHONPATH\"])\n",
    "# # os.system(\"rm -r ~/.matplotlib\")\n",
    "# fm.findfont(\"LiberationMono\", fallback_to_default=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\"resnet34\", features_only=True, num_classes=5, out_indices=[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convit_base\n",
      "convit_small\n",
      "convit_tiny\n",
      "crossvit_9_240\n",
      "crossvit_9_dagger_240\n",
      "crossvit_15_240\n",
      "crossvit_15_dagger_240\n",
      "crossvit_15_dagger_408\n",
      "crossvit_18_240\n",
      "crossvit_18_dagger_240\n",
      "crossvit_18_dagger_408\n",
      "crossvit_base_240\n",
      "crossvit_small_240\n",
      "crossvit_tiny_240\n",
      "davit_base\n",
      "davit_giant\n",
      "davit_huge\n",
      "davit_large\n",
      "davit_small\n",
      "davit_tiny\n",
      "efficientvit_b0\n",
      "efficientvit_b1\n",
      "efficientvit_b2\n",
      "efficientvit_b3\n",
      "efficientvit_m0\n",
      "efficientvit_m1\n",
      "efficientvit_m2\n",
      "efficientvit_m3\n",
      "efficientvit_m4\n",
      "efficientvit_m5\n",
      "fastvit_ma36\n",
      "fastvit_s12\n",
      "fastvit_sa12\n",
      "fastvit_sa24\n",
      "fastvit_sa36\n",
      "fastvit_t8\n",
      "fastvit_t12\n",
      "flexivit_base\n",
      "flexivit_large\n",
      "flexivit_small\n",
      "gcvit_base\n",
      "gcvit_small\n",
      "gcvit_tiny\n",
      "gcvit_xtiny\n",
      "gcvit_xxtiny\n",
      "levit_128\n",
      "levit_128s\n",
      "levit_192\n",
      "levit_256\n",
      "levit_256d\n",
      "levit_384\n",
      "levit_384_s8\n",
      "levit_512\n",
      "levit_512_s8\n",
      "levit_512d\n",
      "levit_conv_128\n",
      "levit_conv_128s\n",
      "levit_conv_192\n",
      "levit_conv_256\n",
      "levit_conv_256d\n",
      "levit_conv_384\n",
      "levit_conv_384_s8\n",
      "levit_conv_512\n",
      "levit_conv_512_s8\n",
      "levit_conv_512d\n",
      "maxvit_base_tf_224\n",
      "maxvit_base_tf_384\n",
      "maxvit_base_tf_512\n",
      "maxvit_large_tf_224\n",
      "maxvit_large_tf_384\n",
      "maxvit_large_tf_512\n",
      "maxvit_nano_rw_256\n",
      "maxvit_pico_rw_256\n",
      "maxvit_rmlp_base_rw_224\n",
      "maxvit_rmlp_base_rw_384\n",
      "maxvit_rmlp_nano_rw_256\n",
      "maxvit_rmlp_pico_rw_256\n",
      "maxvit_rmlp_small_rw_224\n",
      "maxvit_rmlp_small_rw_256\n",
      "maxvit_rmlp_tiny_rw_256\n",
      "maxvit_small_tf_224\n",
      "maxvit_small_tf_384\n",
      "maxvit_small_tf_512\n",
      "maxvit_tiny_pm_256\n",
      "maxvit_tiny_rw_224\n",
      "maxvit_tiny_rw_256\n",
      "maxvit_tiny_tf_224\n",
      "maxvit_tiny_tf_384\n",
      "maxvit_tiny_tf_512\n",
      "maxvit_xlarge_tf_224\n",
      "maxvit_xlarge_tf_384\n",
      "maxvit_xlarge_tf_512\n",
      "maxxvit_rmlp_nano_rw_256\n",
      "maxxvit_rmlp_small_rw_256\n",
      "maxxvit_rmlp_tiny_rw_256\n",
      "maxxvitv2_nano_rw_256\n",
      "maxxvitv2_rmlp_base_rw_224\n",
      "maxxvitv2_rmlp_base_rw_384\n",
      "maxxvitv2_rmlp_large_rw_224\n",
      "mobilevit_s\n",
      "mobilevit_xs\n",
      "mobilevit_xxs\n",
      "mobilevitv2_050\n",
      "mobilevitv2_075\n",
      "mobilevitv2_100\n",
      "mobilevitv2_125\n",
      "mobilevitv2_150\n",
      "mobilevitv2_175\n",
      "mobilevitv2_200\n",
      "mvitv2_base\n",
      "mvitv2_base_cls\n",
      "mvitv2_huge_cls\n",
      "mvitv2_large\n",
      "mvitv2_large_cls\n",
      "mvitv2_small\n",
      "mvitv2_small_cls\n",
      "mvitv2_tiny\n",
      "repvit_m0_9\n",
      "repvit_m1\n",
      "repvit_m1_0\n",
      "repvit_m1_1\n",
      "repvit_m1_5\n",
      "repvit_m2\n",
      "repvit_m2_3\n",
      "repvit_m3\n",
      "samvit_base_patch16\n",
      "samvit_base_patch16_224\n",
      "samvit_huge_patch16\n",
      "samvit_large_patch16\n",
      "tiny_vit_5m_224\n",
      "tiny_vit_11m_224\n",
      "tiny_vit_21m_224\n",
      "tiny_vit_21m_384\n",
      "tiny_vit_21m_512\n",
      "vit_base_patch8_224\n",
      "vit_base_patch14_dinov2\n",
      "vit_base_patch14_reg4_dinov2\n",
      "vit_base_patch16_18x2_224\n",
      "vit_base_patch16_224\n",
      "vit_base_patch16_224_miil\n",
      "vit_base_patch16_384\n",
      "vit_base_patch16_clip_224\n",
      "vit_base_patch16_clip_384\n",
      "vit_base_patch16_clip_quickgelu_224\n",
      "vit_base_patch16_gap_224\n",
      "vit_base_patch16_plus_240\n",
      "vit_base_patch16_reg8_gap_256\n",
      "vit_base_patch16_rpn_224\n",
      "vit_base_patch16_siglip_224\n",
      "vit_base_patch16_siglip_256\n",
      "vit_base_patch16_siglip_384\n",
      "vit_base_patch16_siglip_512\n",
      "vit_base_patch16_xp_224\n",
      "vit_base_patch32_224\n",
      "vit_base_patch32_384\n",
      "vit_base_patch32_clip_224\n",
      "vit_base_patch32_clip_256\n",
      "vit_base_patch32_clip_384\n",
      "vit_base_patch32_clip_448\n",
      "vit_base_patch32_clip_quickgelu_224\n",
      "vit_base_patch32_plus_256\n",
      "vit_base_r26_s32_224\n",
      "vit_base_r50_s16_224\n",
      "vit_base_r50_s16_384\n",
      "vit_base_resnet26d_224\n",
      "vit_base_resnet50d_224\n",
      "vit_giant_patch14_224\n",
      "vit_giant_patch14_clip_224\n",
      "vit_giant_patch14_dinov2\n",
      "vit_giant_patch14_reg4_dinov2\n",
      "vit_giant_patch16_gap_224\n",
      "vit_gigantic_patch14_224\n",
      "vit_gigantic_patch14_clip_224\n",
      "vit_huge_patch14_224\n",
      "vit_huge_patch14_clip_224\n",
      "vit_huge_patch14_clip_336\n",
      "vit_huge_patch14_clip_378\n",
      "vit_huge_patch14_clip_quickgelu_224\n",
      "vit_huge_patch14_clip_quickgelu_378\n",
      "vit_huge_patch14_gap_224\n",
      "vit_huge_patch14_xp_224\n",
      "vit_huge_patch16_gap_448\n",
      "vit_large_patch14_224\n",
      "vit_large_patch14_clip_224\n",
      "vit_large_patch14_clip_336\n",
      "vit_large_patch14_clip_quickgelu_224\n",
      "vit_large_patch14_clip_quickgelu_336\n",
      "vit_large_patch14_dinov2\n",
      "vit_large_patch14_reg4_dinov2\n",
      "vit_large_patch14_xp_224\n",
      "vit_large_patch16_224\n",
      "vit_large_patch16_384\n",
      "vit_large_patch16_siglip_256\n",
      "vit_large_patch16_siglip_384\n",
      "vit_large_patch32_224\n",
      "vit_large_patch32_384\n",
      "vit_large_r50_s32_224\n",
      "vit_large_r50_s32_384\n",
      "vit_medium_patch16_gap_240\n",
      "vit_medium_patch16_gap_256\n",
      "vit_medium_patch16_gap_384\n",
      "vit_medium_patch16_reg4_256\n",
      "vit_medium_patch16_reg4_gap_256\n",
      "vit_relpos_base_patch16_224\n",
      "vit_relpos_base_patch16_cls_224\n",
      "vit_relpos_base_patch16_clsgap_224\n",
      "vit_relpos_base_patch16_plus_240\n",
      "vit_relpos_base_patch16_rpn_224\n",
      "vit_relpos_base_patch32_plus_rpn_256\n",
      "vit_relpos_medium_patch16_224\n",
      "vit_relpos_medium_patch16_cls_224\n",
      "vit_relpos_medium_patch16_rpn_224\n",
      "vit_relpos_small_patch16_224\n",
      "vit_relpos_small_patch16_rpn_224\n",
      "vit_small_patch8_224\n",
      "vit_small_patch14_dinov2\n",
      "vit_small_patch14_reg4_dinov2\n",
      "vit_small_patch16_18x2_224\n",
      "vit_small_patch16_36x1_224\n",
      "vit_small_patch16_224\n",
      "vit_small_patch16_384\n",
      "vit_small_patch32_224\n",
      "vit_small_patch32_384\n",
      "vit_small_r26_s32_224\n",
      "vit_small_r26_s32_384\n",
      "vit_small_resnet26d_224\n",
      "vit_small_resnet50d_s16_224\n",
      "vit_so400m_patch14_siglip_224\n",
      "vit_so400m_patch14_siglip_384\n",
      "vit_srelpos_medium_patch16_224\n",
      "vit_srelpos_small_patch16_224\n",
      "vit_tiny_patch16_224\n",
      "vit_tiny_patch16_384\n",
      "vit_tiny_r_s16_p8_224\n",
      "vit_tiny_r_s16_p8_384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(m) for m in timm.list_models() if \"vit\" in m.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DetrConfig {\n",
       "  \"_name_or_path\": \"facebook/detr-resnet-50\",\n",
       "  \"activation_dropout\": 0.0,\n",
       "  \"activation_function\": \"relu\",\n",
       "  \"architectures\": [\n",
       "    \"DetrForObjectDetection\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"auxiliary_loss\": false,\n",
       "  \"backbone\": \"resnet50\",\n",
       "  \"backbone_config\": null,\n",
       "  \"bbox_cost\": 5,\n",
       "  \"bbox_loss_coefficient\": 5,\n",
       "  \"class_cost\": 1,\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"d_model\": 256,\n",
       "  \"decoder_attention_heads\": 8,\n",
       "  \"decoder_ffn_dim\": 2048,\n",
       "  \"decoder_layerdrop\": 0.0,\n",
       "  \"decoder_layers\": 6,\n",
       "  \"dice_loss_coefficient\": 1,\n",
       "  \"dilation\": false,\n",
       "  \"dropout\": 0.1,\n",
       "  \"encoder_attention_heads\": 8,\n",
       "  \"encoder_ffn_dim\": 2048,\n",
       "  \"encoder_layerdrop\": 0.0,\n",
       "  \"encoder_layers\": 6,\n",
       "  \"eos_coefficient\": 0.1,\n",
       "  \"giou_cost\": 2,\n",
       "  \"giou_loss_coefficient\": 2,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"N/A\",\n",
       "    \"1\": \"person\",\n",
       "    \"2\": \"bicycle\",\n",
       "    \"3\": \"car\",\n",
       "    \"4\": \"motorcycle\",\n",
       "    \"5\": \"airplane\",\n",
       "    \"6\": \"bus\",\n",
       "    \"7\": \"train\",\n",
       "    \"8\": \"truck\",\n",
       "    \"9\": \"boat\",\n",
       "    \"10\": \"traffic light\",\n",
       "    \"11\": \"fire hydrant\",\n",
       "    \"12\": \"street sign\",\n",
       "    \"13\": \"stop sign\",\n",
       "    \"14\": \"parking meter\",\n",
       "    \"15\": \"bench\",\n",
       "    \"16\": \"bird\",\n",
       "    \"17\": \"cat\",\n",
       "    \"18\": \"dog\",\n",
       "    \"19\": \"horse\",\n",
       "    \"20\": \"sheep\",\n",
       "    \"21\": \"cow\",\n",
       "    \"22\": \"elephant\",\n",
       "    \"23\": \"bear\",\n",
       "    \"24\": \"zebra\",\n",
       "    \"25\": \"giraffe\",\n",
       "    \"26\": \"hat\",\n",
       "    \"27\": \"backpack\",\n",
       "    \"28\": \"umbrella\",\n",
       "    \"29\": \"shoe\",\n",
       "    \"30\": \"eye glasses\",\n",
       "    \"31\": \"handbag\",\n",
       "    \"32\": \"tie\",\n",
       "    \"33\": \"suitcase\",\n",
       "    \"34\": \"frisbee\",\n",
       "    \"35\": \"skis\",\n",
       "    \"36\": \"snowboard\",\n",
       "    \"37\": \"sports ball\",\n",
       "    \"38\": \"kite\",\n",
       "    \"39\": \"baseball bat\",\n",
       "    \"40\": \"baseball glove\",\n",
       "    \"41\": \"skateboard\",\n",
       "    \"42\": \"surfboard\",\n",
       "    \"43\": \"tennis racket\",\n",
       "    \"44\": \"bottle\",\n",
       "    \"45\": \"plate\",\n",
       "    \"46\": \"wine glass\",\n",
       "    \"47\": \"cup\",\n",
       "    \"48\": \"fork\",\n",
       "    \"49\": \"knife\",\n",
       "    \"50\": \"spoon\",\n",
       "    \"51\": \"bowl\",\n",
       "    \"52\": \"banana\",\n",
       "    \"53\": \"apple\",\n",
       "    \"54\": \"sandwich\",\n",
       "    \"55\": \"orange\",\n",
       "    \"56\": \"broccoli\",\n",
       "    \"57\": \"carrot\",\n",
       "    \"58\": \"hot dog\",\n",
       "    \"59\": \"pizza\",\n",
       "    \"60\": \"donut\",\n",
       "    \"61\": \"cake\",\n",
       "    \"62\": \"chair\",\n",
       "    \"63\": \"couch\",\n",
       "    \"64\": \"potted plant\",\n",
       "    \"65\": \"bed\",\n",
       "    \"66\": \"mirror\",\n",
       "    \"67\": \"dining table\",\n",
       "    \"68\": \"window\",\n",
       "    \"69\": \"desk\",\n",
       "    \"70\": \"toilet\",\n",
       "    \"71\": \"door\",\n",
       "    \"72\": \"tv\",\n",
       "    \"73\": \"laptop\",\n",
       "    \"74\": \"mouse\",\n",
       "    \"75\": \"remote\",\n",
       "    \"76\": \"keyboard\",\n",
       "    \"77\": \"cell phone\",\n",
       "    \"78\": \"microwave\",\n",
       "    \"79\": \"oven\",\n",
       "    \"80\": \"toaster\",\n",
       "    \"81\": \"sink\",\n",
       "    \"82\": \"refrigerator\",\n",
       "    \"83\": \"blender\",\n",
       "    \"84\": \"book\",\n",
       "    \"85\": \"clock\",\n",
       "    \"86\": \"vase\",\n",
       "    \"87\": \"scissors\",\n",
       "    \"88\": \"teddy bear\",\n",
       "    \"89\": \"hair drier\",\n",
       "    \"90\": \"toothbrush\"\n",
       "  },\n",
       "  \"init_std\": 0.02,\n",
       "  \"init_xavier_std\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"label2id\": {\n",
       "    \"N/A\": 0,\n",
       "    \"airplane\": 5,\n",
       "    \"apple\": 53,\n",
       "    \"backpack\": 27,\n",
       "    \"banana\": 52,\n",
       "    \"baseball bat\": 39,\n",
       "    \"baseball glove\": 40,\n",
       "    \"bear\": 23,\n",
       "    \"bed\": 65,\n",
       "    \"bench\": 15,\n",
       "    \"bicycle\": 2,\n",
       "    \"bird\": 16,\n",
       "    \"blender\": 83,\n",
       "    \"boat\": 9,\n",
       "    \"book\": 84,\n",
       "    \"bottle\": 44,\n",
       "    \"bowl\": 51,\n",
       "    \"broccoli\": 56,\n",
       "    \"bus\": 6,\n",
       "    \"cake\": 61,\n",
       "    \"car\": 3,\n",
       "    \"carrot\": 57,\n",
       "    \"cat\": 17,\n",
       "    \"cell phone\": 77,\n",
       "    \"chair\": 62,\n",
       "    \"clock\": 85,\n",
       "    \"couch\": 63,\n",
       "    \"cow\": 21,\n",
       "    \"cup\": 47,\n",
       "    \"desk\": 69,\n",
       "    \"dining table\": 67,\n",
       "    \"dog\": 18,\n",
       "    \"donut\": 60,\n",
       "    \"door\": 71,\n",
       "    \"elephant\": 22,\n",
       "    \"eye glasses\": 30,\n",
       "    \"fire hydrant\": 11,\n",
       "    \"fork\": 48,\n",
       "    \"frisbee\": 34,\n",
       "    \"giraffe\": 25,\n",
       "    \"hair drier\": 89,\n",
       "    \"handbag\": 31,\n",
       "    \"hat\": 26,\n",
       "    \"horse\": 19,\n",
       "    \"hot dog\": 58,\n",
       "    \"keyboard\": 76,\n",
       "    \"kite\": 38,\n",
       "    \"knife\": 49,\n",
       "    \"laptop\": 73,\n",
       "    \"microwave\": 78,\n",
       "    \"mirror\": 66,\n",
       "    \"motorcycle\": 4,\n",
       "    \"mouse\": 74,\n",
       "    \"orange\": 55,\n",
       "    \"oven\": 79,\n",
       "    \"parking meter\": 14,\n",
       "    \"person\": 1,\n",
       "    \"pizza\": 59,\n",
       "    \"plate\": 45,\n",
       "    \"potted plant\": 64,\n",
       "    \"refrigerator\": 82,\n",
       "    \"remote\": 75,\n",
       "    \"sandwich\": 54,\n",
       "    \"scissors\": 87,\n",
       "    \"sheep\": 20,\n",
       "    \"shoe\": 29,\n",
       "    \"sink\": 81,\n",
       "    \"skateboard\": 41,\n",
       "    \"skis\": 35,\n",
       "    \"snowboard\": 36,\n",
       "    \"spoon\": 50,\n",
       "    \"sports ball\": 37,\n",
       "    \"stop sign\": 13,\n",
       "    \"street sign\": 12,\n",
       "    \"suitcase\": 33,\n",
       "    \"surfboard\": 42,\n",
       "    \"teddy bear\": 88,\n",
       "    \"tennis racket\": 43,\n",
       "    \"tie\": 32,\n",
       "    \"toaster\": 80,\n",
       "    \"toilet\": 70,\n",
       "    \"toothbrush\": 90,\n",
       "    \"traffic light\": 10,\n",
       "    \"train\": 7,\n",
       "    \"truck\": 8,\n",
       "    \"tv\": 72,\n",
       "    \"umbrella\": 28,\n",
       "    \"vase\": 86,\n",
       "    \"window\": 68,\n",
       "    \"wine glass\": 46,\n",
       "    \"zebra\": 24\n",
       "  },\n",
       "  \"mask_loss_coefficient\": 1,\n",
       "  \"max_position_embeddings\": 1024,\n",
       "  \"model_type\": \"detr\",\n",
       "  \"num_channels\": 3,\n",
       "  \"num_hidden_layers\": 6,\n",
       "  \"num_queries\": 100,\n",
       "  \"position_embedding_type\": \"sine\",\n",
       "  \"scale_embedding\": false,\n",
       "  \"transformers_version\": \"4.34.0\",\n",
       "  \"use_pretrained_backbone\": true,\n",
       "  \"use_timm_backbone\": true\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoConfig.from_pretrained( \"facebook/detr-resnet-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DetrForObjectDetection were not initialized from the model checkpoint at facebook/detr-resnet-50 and are newly initialized because the shapes did not match:\n",
      "- class_labels_classifier.weight: found shape torch.Size([92, 256]) in the checkpoint and torch.Size([11, 256]) in the model instantiated\n",
      "- class_labels_classifier.bias: found shape torch.Size([92]) in the checkpoint and torch.Size([11]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForObjectDetection.from_pretrained(\n",
    "    \"facebook/detr-resnet-50\", num_labels=10, ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 7, 7])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet34()\n",
    "# model.fc = nn.Linear(model.fc.in_features, 32*32*3)\n",
    "x = torch.zeros(1, 3, 224, 224)\n",
    "x = model.conv1(x)\n",
    "x = model.bn1(x)\n",
    "x = model.relu(x)\n",
    "x = model.maxpool(x)\n",
    "\n",
    "x = model.layer1(x)\n",
    "x = model.layer2(x)\n",
    "x = model.layer3(x)\n",
    "x = model.layer4(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "ms = timm.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['efficientformer_l1',\n",
       " 'efficientformer_l3',\n",
       " 'efficientformer_l7',\n",
       " 'efficientformerv2_l',\n",
       " 'efficientformerv2_s0',\n",
       " 'efficientformerv2_s1',\n",
       " 'efficientformerv2_s2',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b0_g8_gn',\n",
       " 'efficientnet_b0_g16_evos',\n",
       " 'efficientnet_b0_gn',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b2a',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_g8_gn',\n",
       " 'efficientnet_b3_gn',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b3a',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_b8',\n",
       " 'efficientnet_cc_b0_4e',\n",
       " 'efficientnet_cc_b0_8e',\n",
       " 'efficientnet_cc_b1_8e',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_el_pruned',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_es_pruned',\n",
       " 'efficientnet_l2',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnet_lite1',\n",
       " 'efficientnet_lite2',\n",
       " 'efficientnet_lite3',\n",
       " 'efficientnet_lite4',\n",
       " 'efficientnetv2_l',\n",
       " 'efficientnetv2_m',\n",
       " 'efficientnetv2_rw_m',\n",
       " 'efficientnetv2_rw_s',\n",
       " 'efficientnetv2_rw_t',\n",
       " 'efficientnetv2_s',\n",
       " 'efficientnetv2_xl',\n",
       " 'efficientvit_b0',\n",
       " 'efficientvit_b1',\n",
       " 'efficientvit_b2',\n",
       " 'efficientvit_b3',\n",
       " 'efficientvit_m0',\n",
       " 'efficientvit_m1',\n",
       " 'efficientvit_m2',\n",
       " 'efficientvit_m3',\n",
       " 'efficientvit_m4',\n",
       " 'efficientvit_m5',\n",
       " 'gc_efficientnetv2_rw_t',\n",
       " 'tf_efficientnet_b0',\n",
       " 'tf_efficientnet_b1',\n",
       " 'tf_efficientnet_b2',\n",
       " 'tf_efficientnet_b3',\n",
       " 'tf_efficientnet_b4',\n",
       " 'tf_efficientnet_b5',\n",
       " 'tf_efficientnet_b6',\n",
       " 'tf_efficientnet_b7',\n",
       " 'tf_efficientnet_b8',\n",
       " 'tf_efficientnet_cc_b0_4e',\n",
       " 'tf_efficientnet_cc_b0_8e',\n",
       " 'tf_efficientnet_cc_b1_8e',\n",
       " 'tf_efficientnet_el',\n",
       " 'tf_efficientnet_em',\n",
       " 'tf_efficientnet_es',\n",
       " 'tf_efficientnet_l2',\n",
       " 'tf_efficientnet_lite0',\n",
       " 'tf_efficientnet_lite1',\n",
       " 'tf_efficientnet_lite2',\n",
       " 'tf_efficientnet_lite3',\n",
       " 'tf_efficientnet_lite4',\n",
       " 'tf_efficientnetv2_b0',\n",
       " 'tf_efficientnetv2_b1',\n",
       " 'tf_efficientnetv2_b2',\n",
       " 'tf_efficientnetv2_b3',\n",
       " 'tf_efficientnetv2_l',\n",
       " 'tf_efficientnetv2_m',\n",
       " 'tf_efficientnetv2_s',\n",
       " 'tf_efficientnetv2_xl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in ms if \"efficient\" in m.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ByobNet(\n",
       "  (stem): ConvNormAct(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNormAct2d(\n",
       "      32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (stages): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (conv1_1x1): ConvNormAct(\n",
       "          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv2_kxk): ConvNormAct(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv2b_kxk): Identity()\n",
       "        (attn): Identity()\n",
       "        (conv3_1x1): ConvNormAct(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "        )\n",
       "        (attn_last): Identity()\n",
       "        (drop_path): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (conv1_1x1): ConvNormAct(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv2_kxk): ConvNormAct(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv2b_kxk): Identity()\n",
       "        (attn): Identity()\n",
       "        (conv3_1x1): ConvNormAct(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "        )\n",
       "        (attn_last): Identity()\n",
       "        (drop_path): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (shortcut): Identity()\n",
       "        (conv1_1x1): ConvNormAct(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv2_kxk): ConvNormAct(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv2b_kxk): Identity()\n",
       "        (attn): Identity()\n",
       "        (conv3_1x1): ConvNormAct(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "        )\n",
       "        (attn_last): Identity()\n",
       "        (drop_path): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (conv1_1x1): ConvNormAct(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv2_kxk): ConvNormAct(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv2b_kxk): Identity()\n",
       "        (attn): Identity()\n",
       "        (conv3_1x1): ConvNormAct(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "        )\n",
       "        (attn_last): Identity()\n",
       "        (drop_path): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (1): MobileVitV2Block(\n",
       "        (conv_kxk): ConvNormAct(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv_1x1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (transformer): Sequential(\n",
       "          (0): LinearTransformerBlock(\n",
       "            (norm1): GroupNorm1(1, 128, eps=1e-05, affine=True)\n",
       "            (attn): LinearSelfAttention(\n",
       "              (qkv_proj): Conv2d(128, 257, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (out_proj): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (out_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.000)\n",
       "            (norm2): GroupNorm1(1, 128, eps=1e-05, affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): SiLU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.000)\n",
       "          )\n",
       "          (1): LinearTransformerBlock(\n",
       "            (norm1): GroupNorm1(1, 128, eps=1e-05, affine=True)\n",
       "            (attn): LinearSelfAttention(\n",
       "              (qkv_proj): Conv2d(128, 257, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (out_proj): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (out_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.000)\n",
       "            (norm2): GroupNorm1(1, 128, eps=1e-05, affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): SiLU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.000)\n",
       "          )\n",
       "        )\n",
       "        (norm): GroupNorm1(1, 128, eps=1e-05, affine=True)\n",
       "        (conv_proj): ConvNormAct(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (conv1_1x1): ConvNormAct(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv2_kxk): ConvNormAct(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv2b_kxk): Identity()\n",
       "        (attn): Identity()\n",
       "        (conv3_1x1): ConvNormAct(\n",
       "          (conv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "        )\n",
       "        (attn_last): Identity()\n",
       "        (drop_path): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (1): MobileVitV2Block(\n",
       "        (conv_kxk): ConvNormAct(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv_1x1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (transformer): Sequential(\n",
       "          (0): LinearTransformerBlock(\n",
       "            (norm1): GroupNorm1(1, 192, eps=1e-05, affine=True)\n",
       "            (attn): LinearSelfAttention(\n",
       "              (qkv_proj): Conv2d(192, 385, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (out_proj): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (out_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.000)\n",
       "            (norm2): GroupNorm1(1, 192, eps=1e-05, affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): SiLU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.000)\n",
       "          )\n",
       "          (1): LinearTransformerBlock(\n",
       "            (norm1): GroupNorm1(1, 192, eps=1e-05, affine=True)\n",
       "            (attn): LinearSelfAttention(\n",
       "              (qkv_proj): Conv2d(192, 385, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (out_proj): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (out_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.000)\n",
       "            (norm2): GroupNorm1(1, 192, eps=1e-05, affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): SiLU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.000)\n",
       "          )\n",
       "          (2): LinearTransformerBlock(\n",
       "            (norm1): GroupNorm1(1, 192, eps=1e-05, affine=True)\n",
       "            (attn): LinearSelfAttention(\n",
       "              (qkv_proj): Conv2d(192, 385, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (out_proj): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (out_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.000)\n",
       "            (norm2): GroupNorm1(1, 192, eps=1e-05, affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): SiLU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.000)\n",
       "          )\n",
       "          (3): LinearTransformerBlock(\n",
       "            (norm1): GroupNorm1(1, 192, eps=1e-05, affine=True)\n",
       "            (attn): LinearSelfAttention(\n",
       "              (qkv_proj): Conv2d(192, 385, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (out_proj): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (out_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.000)\n",
       "            (norm2): GroupNorm1(1, 192, eps=1e-05, affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): SiLU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.000)\n",
       "          )\n",
       "        )\n",
       "        (norm): GroupNorm1(1, 192, eps=1e-05, affine=True)\n",
       "        (conv_proj): ConvNormAct(\n",
       "          (conv): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (conv1_1x1): ConvNormAct(\n",
       "          (conv): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv2_kxk): ConvNormAct(\n",
       "          (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=768, bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv2b_kxk): Identity()\n",
       "        (attn): Identity()\n",
       "        (conv3_1x1): ConvNormAct(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "        )\n",
       "        (attn_last): Identity()\n",
       "        (drop_path): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (1): MobileVitV2Block(\n",
       "        (conv_kxk): ConvNormAct(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv_1x1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (transformer): Sequential(\n",
       "          (0): LinearTransformerBlock(\n",
       "            (norm1): GroupNorm1(1, 256, eps=1e-05, affine=True)\n",
       "            (attn): LinearSelfAttention(\n",
       "              (qkv_proj): Conv2d(256, 513, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (out_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (out_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.000)\n",
       "            (norm2): GroupNorm1(1, 256, eps=1e-05, affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): SiLU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.000)\n",
       "          )\n",
       "          (1): LinearTransformerBlock(\n",
       "            (norm1): GroupNorm1(1, 256, eps=1e-05, affine=True)\n",
       "            (attn): LinearSelfAttention(\n",
       "              (qkv_proj): Conv2d(256, 513, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (out_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (out_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.000)\n",
       "            (norm2): GroupNorm1(1, 256, eps=1e-05, affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): SiLU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.000)\n",
       "          )\n",
       "          (2): LinearTransformerBlock(\n",
       "            (norm1): GroupNorm1(1, 256, eps=1e-05, affine=True)\n",
       "            (attn): LinearSelfAttention(\n",
       "              (qkv_proj): Conv2d(256, 513, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (out_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (out_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.000)\n",
       "            (norm2): GroupNorm1(1, 256, eps=1e-05, affine=True)\n",
       "            (mlp): ConvMlp(\n",
       "              (fc1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): SiLU()\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.000)\n",
       "          )\n",
       "        )\n",
       "        (norm): GroupNorm1(1, 256, eps=1e-05, affine=True)\n",
       "        (conv_proj): ConvNormAct(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNormAct2d(\n",
       "            512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Identity()\n",
       "  (head): ClassifierHead(\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (flatten): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model(\"mobilevitv2_100\", num_classes=10, img_size=99)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 7, 7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16()\n",
    "X = torch.ones((1, 3, 224, 244))\n",
    "model.features(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.AlexNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetModel(\n",
       "  (embedder): ResNetEmbeddings(\n",
       "    (embedder): ResNetConvLayer(\n",
       "      (convolution): Conv2d(2, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (encoder): ResNetEncoder(\n",
       "    (stages): ModuleList(\n",
       "      (0): ResNetStage(\n",
       "        (layers): Sequential(\n",
       "          (0): ResNetBottleNeckLayer(\n",
       "            (shortcut): ResNetShortCut(\n",
       "              (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (2): ResNetConvLayer(\n",
       "                (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (1): ResNetBottleNeckLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (2): ResNetConvLayer(\n",
       "                (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (2): ResNetBottleNeckLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (2): ResNetConvLayer(\n",
       "                (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ResNetStage(\n",
       "        (layers): Sequential(\n",
       "          (0): ResNetBottleNeckLayer(\n",
       "            (shortcut): ResNetShortCut(\n",
       "              (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (2): ResNetConvLayer(\n",
       "                (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (1): ResNetBottleNeckLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (2): ResNetConvLayer(\n",
       "                (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (2): ResNetBottleNeckLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (2): ResNetConvLayer(\n",
       "                (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (3): ResNetBottleNeckLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (2): ResNetConvLayer(\n",
       "                (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ResNetStage(\n",
       "        (layers): Sequential(\n",
       "          (0): ResNetBottleNeckLayer(\n",
       "            (shortcut): ResNetShortCut(\n",
       "              (convolution): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (2): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (1): ResNetBottleNeckLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (2): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (2): ResNetBottleNeckLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (2): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (3): ResNetBottleNeckLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (2): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (4): ResNetBottleNeckLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (2): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (5): ResNetBottleNeckLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (2): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ResNetStage(\n",
       "        (layers): Sequential(\n",
       "          (0): ResNetBottleNeckLayer(\n",
       "            (shortcut): ResNetShortCut(\n",
       "              (convolution): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (2): ResNetConvLayer(\n",
       "                (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (1): ResNetBottleNeckLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (2): ResNetConvLayer(\n",
       "                (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (2): ResNetBottleNeckLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (2): ResNetConvLayer(\n",
       "                (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ResNetBackbone, ResNetConfig, ResNetModel\n",
    "\n",
    "config = ResNetConfig(num_channels=2)\n",
    "\n",
    "ResNetBackbone(config)\n",
    "ResNetModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 192, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (patch_drop): Identity()\n",
       "  (norm_pre): Identity()\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "  (fc_norm): Identity()\n",
       "  (head_drop): Dropout(p=0.0, inplace=False)\n",
       "  (head): Linear(in_features=192, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model(\n",
    "    \"vit_tiny_patch16_224\",\n",
    "    num_classes=2,\n",
    "    pretrained=False,\n",
    "    #features_only=True,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = models.detection.fasterrcnn_resnet50_fpn(num_classes=5)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 224, 224]),\n",
       " [{'labels': tensor([1]), 'boxes': tensor([[ 68,  48, 136,  77]])},\n",
       "  {'labels': tensor([4]), 'boxes': tensor([[ 68,  48, 136,  77]])}])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(2, 3, 224, 224).float()\n",
    "classes = torch.randint(1, 6, size=(2,))\n",
    "\n",
    "rand_xy = torch.randint(0, 224//2, size=(2,))\n",
    "rand_xy2 = torch.randint(0, 224//2, size=(2,))\n",
    "\n",
    "y = [{\"labels\": torch.tensor([c]), \"boxes\": torch.tensor([*rand_xy.tolist(), *(rand_xy + rand_xy2).tolist()]).unsqueeze(dim=0)} for c in classes]\n",
    "\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_classifier': tensor(1.6939, grad_fn=<NllLossBackward0>),\n",
       " 'loss_box_reg': tensor(0.0002, grad_fn=<DivBackward0>),\n",
       " 'loss_objectness': tensor(0.6855, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
       " 'loss_rpn_box_reg': tensor(0.0058, grad_fn=<DivBackward0>)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdd-2XWLAjSi-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
